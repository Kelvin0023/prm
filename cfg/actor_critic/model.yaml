_target_: rrl.algo.trainer.Trainer

network:
  actor_units: [512, 512, 256, 128]
  critic_units: [512, 512, 256, 128]

learning_rate: 5e-4
kl_threshold: 0.016
weight_decay: 0.0
# PPO batch collection
num_mini_batches: 4
bc_batch_size: 16384

actor_mini_epochs: 5
critic_mini_epochs: 8
bc_mini_epochs: 5

# PPO loss setting
clip_value: True
entropy_coef: 0.0
e_clip: 0.2
bounds_loss_coef: 0.0001
critic_coef: 4.0
bc_coef: 1.0

# grad clipping
truncate_grads: True
grad_norm: 1.0


